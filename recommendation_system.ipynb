{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Recommendation System**"
      ],
      "metadata": {
        "id": "yAbLI7PlEFrY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary\n",
        "\n",
        "This notebook demonstrates the complete pipeline for building a recommendation system, from synthetic data generation to evaluation. The project includes generating diverse user and workout data, preprocessing it for collaborative and content-based filtering, and implementing a hybrid recommendation model. By combining collaborative filtering with content attributes like demographics, the system addresses key challenges such as personalization and the cold-start problem. The evaluation using metrics such as RMSE, MAE, precision, and recall validates the system’s effectiveness. Future improvements include testing on real-world data, exploring advanced models, and preparing the system for deployment. These steps aim to ensure a scalable and robust solution."
      ],
      "metadata": {
        "id": "gU5L5EqdKciA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-surprise\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ombq8EDGEEB",
        "outputId": "1911020e-fc20-4a67-8842-328c87350aa3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-surprise\n",
            "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/154.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m153.6/154.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.13.1)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp311-cp311-linux_x86_64.whl size=2505187 sha256=3fb0e89fd2b2a7bcfdc74efa47fc688570a1c5a86c8b8fd06bfe97bf4e4cc6b0\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/8f/6e/7e2899163e2d85d8266daab4aa1cdabec7a6c56f83c015b5af\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise\n",
            "Successfully installed scikit-surprise-1.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YNsF2ke445QE"
      },
      "outputs": [],
      "source": [
        "# Importing required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from surprise import Dataset, Reader, SVD\n",
        "from surprise.model_selection import train_test_split, cross_validate\n",
        "from surprise import accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generating Synthetic Data**"
      ],
      "metadata": {
        "id": "5mae7IfUColT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since real-world datasets were not provided, generating synthetic data was essential for this project. I chose metrics like calories burned, workout duration, heart rate, and VO2 Max because they reflect various aspects of fitness engagement and intensity. These metrics can help personalize recommendations based on user preferences and performance.\n",
        "\n",
        "To ensure diversity in the dataset, I used random sampling for workout types and generated random values within realistic ranges for each metric. This helps simulate varied user profiles and workout patterns, making the dataset more robust for testing the recommendation system."
      ],
      "metadata": {
        "id": "st25fISv0_Ku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameters for synthetic data\n",
        "np.random.seed(42)  # Ensures reproducibility\n",
        "user_ids = [f\"user_{i}\" for i in range(1, 101)]  # 100 users\n",
        "workout_types = ['Yoga', 'Cardio', 'Strength', 'HIIT', 'Pilates', 'Dance', 'CrossFit', 'Zumba', 'Cycling']\n",
        "\n",
        "# Generate synthetic dataset\n",
        "data = []\n",
        "for user_id in user_ids:\n",
        "    for workout in random.sample(workout_types, 4):  # Each user performs 4 random workouts\n",
        "        calories = np.random.randint(150, 800)\n",
        "        duration = np.random.randint(15, 120)\n",
        "        heart_rate = np.random.randint(80, 180)\n",
        "        vo2_max = round(np.random.uniform(30, 60), 2)\n",
        "        data.append([user_id, workout, calories, duration, heart_rate, vo2_max])\n",
        "\n",
        "# Convert data to DataFrame\n",
        "df = pd.DataFrame(data, columns=[\n",
        "    'User ID', 'Workout Type', 'Calories Burned', 'Workout Duration', 'Heart Rate', 'VO2 Max'\n",
        "])\n",
        "\n",
        "# Display the first few rows\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7CxGJsmEgTK",
        "outputId": "98af0676-ff1a-424c-c286-a7f13b5df90b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  User ID Workout Type  Calories Burned  Workout Duration  Heart Rate  VO2 Max\n",
            "0  user_1        Dance              252                66         172    35.50\n",
            "1  user_1        Zumba              221                75         100    34.68\n",
            "2  user_1      Pilates              616               101         154    43.78\n",
            "3  user_1         HIIT              522               114         103    49.53\n",
            "4  user_2      Pilates              458                16         167    54.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Normalizing Data**"
      ],
      "metadata": {
        "id": "1cE5OUWlFW0d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Why Normalize?:** The numeric features like calories burned and workout duration are on different scales, which could dominate similarity calculations or model training. Normalizing these features ensures that all metrics contribute equally to the recommendations."
      ],
      "metadata": {
        "id": "Z_wJH54j1PPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize numeric features\n",
        "scaler = MinMaxScaler()\n",
        "df[['Calories Burned', 'Workout Duration', 'Heart Rate', 'VO2 Max']] = scaler.fit_transform(\n",
        "    df[['Calories Burned', 'Workout Duration', 'Heart Rate', 'VO2 Max']]\n",
        ")\n",
        "\n",
        "# Encode workout types as numeric categories\n",
        "df['Workout Type'] = df['Workout Type'].astype('category').cat.codes\n",
        "\n",
        "# Display data summary\n",
        "print(df.describe())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ObDRZUMFJSr",
        "outputId": "77d519e3-9dad-4ce4-bb21-653bb019b457"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Workout Type  Calories Burned  Workout Duration  Heart Rate     VO2 Max\n",
            "count    400.000000       400.000000        400.000000  400.000000  400.000000\n",
            "mean       3.665000         0.476283          0.511490    0.488061    0.527324\n",
            "std        2.514674         0.290773          0.291390    0.302032    0.299362\n",
            "min        0.000000         0.000000          0.000000    0.000000    0.000000\n",
            "25%        2.000000         0.221705          0.278846    0.224490    0.262719\n",
            "50%        4.000000         0.493798          0.548077    0.469388    0.540768\n",
            "75%        6.000000         0.722481          0.750000    0.765306    0.809552\n",
            "max        8.000000         1.000000          1.000000    1.000000    1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Preparation**"
      ],
      "metadata": {
        "id": "3E2V8hL8Gprn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used calories burned as the target rating for the recommendation system because it is a key indicator of workout effectiveness and aligns with the goal of recommending workouts that suit user needs.\n",
        "\n",
        "The choice to use collaborative filtering was driven by its ability to leverage user-item interactions. While content-based methods could be explored, starting with collaborative filtering allows us to test the fundamental recommendation process."
      ],
      "metadata": {
        "id": "eQZdQo2g1ckE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the rating matrix (use Calories Burned as the target rating)\n",
        "rating_data = df[['User ID', 'Workout Type', 'Calories Burned']]\n",
        "\n",
        "# Prepare dataset for Surprise library\n",
        "reader = Reader(rating_scale=(0, 1))\n",
        "data = Dataset.load_from_df(rating_data, reader)\n"
      ],
      "metadata": {
        "id": "2Vjlm4UKFg_K"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Split data into training and test sets\n",
        "# trainset, testset = train_test_split(data, test_size=0.2)\n",
        "\n",
        "# print(f\"Training set size: {len(trainset.all_ratings())}\")\n",
        "# print(f\"Test set size: {len(testset)}\")\n",
        "\n",
        "# Split data into training and test sets\n",
        "trainset, testset = train_test_split(data, test_size=0.2)\n",
        "\n",
        "# Get the number of ratings in the training set\n",
        "trainset_ratings_count = sum(1 for _ in trainset.all_ratings())\n",
        "testset_ratings_count = len(testset)\n",
        "\n",
        "print(f\"Training set size: {trainset_ratings_count}\")\n",
        "print(f\"Test set size: {testset_ratings_count}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "el0fhyKiFkHc",
        "outputId": "8f0a858e-9a68-4d84-ee13-45f4f22942d7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 320\n",
            "Test set size: 80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training the SVD Model**"
      ],
      "metadata": {
        "id": "FLe1lbeNGxdG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Why SVD?:** Singular Value Decomposition (SVD) is a popular algorithm for collaborative filtering. It works by decomposing the user-item interaction matrix into latent factors, capturing hidden patterns in user preferences and workout attributes.\n",
        "\n",
        "While SVD is effective for sparse matrices, it may not capture contextual features like time of day or user demographics. These limitations will be addressed in the hybrid approach later."
      ],
      "metadata": {
        "id": "9mBZpt931xJK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the SVD model\n",
        "svd = SVD()\n",
        "svd.fit(trainset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3Xv_i4bFl-M",
        "outputId": "874f323c-3d40-4940-ced2-ff25c4b4c0ef"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7c46d4ffd450>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Evaluation**"
      ],
      "metadata": {
        "id": "fcNf7e0iHAgH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To ensure a comprehensive evaluation, I used RMSE and MAE for accuracy and precision/recall for relevance. These metrics provide insights into both prediction quality and recommendation effectiveness.\n",
        "\n",
        "To validate the model's robustness, I used 5-fold cross-validation. This method helps identify performance consistency across different data splits.\n",
        "\n",
        "Precision and recall trade-offs are crucial in recommendation systems. For example, high precision might result in fewer but highly relevant recommendations, while high recall might cover more relevant items but include noise."
      ],
      "metadata": {
        "id": "6WsvR8_g18ok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross-validate the model\n",
        "cv_results = cross_validate(svd, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
        "\n",
        "\n",
        "### 4. Ranking-Based Evaluation for SVD Model\n",
        "\n",
        "# Generate ground truth for evaluation\n",
        "import random\n",
        "ground_truth = {user_id: random.sample(df[df['User ID'] == user_id]['Workout Type'].tolist(), 2)\n",
        "                for user_id in user_ids if len(df[df['User ID'] == user_id]['Workout Type']) >= 2}\n",
        "\n",
        "# Function to predict and rank top-N recommendations\n",
        "def recommend_top_n_svd(user_id, num_recommendations=3):\n",
        "    predicted_ratings = {workout: svd.predict(user_id, workout).est for workout in df['Workout Type'].unique()}\n",
        "    ranked_workouts = sorted(predicted_ratings, key=predicted_ratings.get, reverse=True)\n",
        "    return ranked_workouts[:num_recommendations]\n",
        "\n",
        "# Evaluate precision and recall\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "\n",
        "for user_id, actual_workouts in ground_truth.items():\n",
        "    recommended_workouts = recommend_top_n_svd(user_id, num_recommendations=3)\n",
        "    true_positives = len(set(recommended_workouts) & set(actual_workouts))\n",
        "    precision = true_positives / len(recommended_workouts) if recommended_workouts else 0\n",
        "    recall = true_positives / len(actual_workouts) if actual_workouts else 0\n",
        "\n",
        "    precision_scores.append(precision)\n",
        "    recall_scores.append(recall)\n",
        "\n",
        "# Calculate average precision and recall\n",
        "average_precision = sum(precision_scores) / len(precision_scores)\n",
        "average_recall = sum(recall_scores) / len(recall_scores)\n",
        "\n",
        "print(f\"Baseline Model - Average Precision: {average_precision:.2f}\")\n",
        "print(f\"Baseline Model - Average Recall: {average_recall:.2f}\")\n",
        "\n",
        "# Split data into training and test sets\n",
        "trainset, testset = train_test_split(data, test_size=0.2)\n",
        "\n",
        "# Train the SVD model\n",
        "svd = SVD()\n",
        "svd.fit(trainset)\n",
        "\n",
        "# Evaluate the model using cross-validation\n",
        "print(\"\\nCross-Validation Results:\")\n",
        "cv_results = cross_validate(svd, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
        "\n",
        "# Evaluate on the test set\n",
        "predictions = svd.test(testset)\n",
        "\n",
        "# Calculate performance metrics\n",
        "rmse = accuracy.rmse(predictions)\n",
        "mae = accuracy.mae(predictions)\n",
        "\n",
        "print(f\"RMSE: {rmse}\")\n",
        "print(f\"MAE: {mae}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lULUqLsb-1hL",
        "outputId": "22a10124-6ce7-4367-afc7-15d643dbeb63"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "RMSE (testset)    0.3114  0.3080  0.3320  0.2994  0.3075  0.3117  0.0109  \n",
            "MAE (testset)     0.2565  0.2585  0.2825  0.2487  0.2541  0.2601  0.0117  \n",
            "Fit time          0.00    0.00    0.00    0.00    0.00    0.00    0.00    \n",
            "Test time         0.00    0.00    0.00    0.00    0.00    0.00    0.00    \n",
            "Baseline Model - Average Precision: 0.20\n",
            "Baseline Model - Average Recall: 0.30\n",
            "\n",
            "Cross-Validation Results:\n",
            "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "RMSE (testset)    0.3153  0.2936  0.3216  0.3027  0.3287  0.3124  0.0127  \n",
            "MAE (testset)     0.2651  0.2481  0.2726  0.2525  0.2806  0.2638  0.0122  \n",
            "Fit time          0.00    0.00    0.00    0.00    0.00    0.00    0.00    \n",
            "Test time         0.00    0.00    0.00    0.00    0.00    0.00    0.00    \n",
            "RMSE: 0.2484\n",
            "MAE:  0.2007\n",
            "RMSE: 0.24837051864428578\n",
            "MAE: 0.20067740872283193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict for a specific user and workout\n",
        "user_id = \"user_10\"\n",
        "workout_type = 3  # Example: Encoded value for 'HIIT'\n",
        "\n",
        "predicted_rating = svd.predict(user_id, workout_type)\n",
        "print(f\"Predicted Rating for {user_id} on workout {workout_type}: {predicted_rating.est:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGxz6LYlFpHw",
        "outputId": "66636eb0-3f1c-46a7-9f2f-81a669cfe7a9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Rating for user_10 on workout 3: 0.30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extending the Dataset by Incorporating Demographics and Contextual Features**"
      ],
      "metadata": {
        "id": "x-oMG1BsMdLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add demographic and contextual features\n",
        "ages = np.random.randint(18, 65, len(user_ids))  # Ages between 18 and 65\n",
        "genders = [random.choice(['Male', 'Female', 'Non-binary']) for _ in user_ids]\n",
        "fitness_levels = [random.choice(['Beginner', 'Intermediate', 'Advanced']) for _ in user_ids]\n",
        "time_of_day = ['Morning', 'Afternoon', 'Evening']\n",
        "\n",
        "# Map fitness levels to numeric categories\n",
        "fitness_level_mapping = {'Beginner': 1, 'Intermediate': 2, 'Advanced': 3}\n",
        "\n",
        "# Extend synthetic data generation with demographics\n",
        "extended_data = []\n",
        "for i, user_id in enumerate(user_ids):\n",
        "    for workout in random.sample(workout_types, 4):\n",
        "        calories = np.random.randint(150, 800)\n",
        "        duration = np.random.randint(15, 120)\n",
        "        heart_rate = np.random.randint(80, 180)\n",
        "        vo2_max = round(np.random.uniform(30, 60), 2)\n",
        "        time = random.choice(time_of_day)\n",
        "        extended_data.append([\n",
        "            user_id, workout, calories, duration, heart_rate, vo2_max,\n",
        "            ages[i], genders[i], fitness_level_mapping[fitness_levels[i]], time\n",
        "        ])\n",
        "\n",
        "# Create DataFrame for extended data\n",
        "df_extended = pd.DataFrame(extended_data, columns=[\n",
        "    'User ID', 'Workout Type', 'Calories Burned', 'Workout Duration', 'Heart Rate', 'VO2 Max',\n",
        "    'Age', 'Gender', 'Fitness Level', 'Time of Day'\n",
        "])\n",
        "\n",
        "# Convert categorical features to numeric\n",
        "df_extended['Gender'] = df_extended['Gender'].astype('category').cat.codes\n",
        "df_extended['Time of Day'] = df_extended['Time of Day'].astype('category').cat.codes\n",
        "\n",
        "print(df_extended.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewklXAKWKQqe",
        "outputId": "c846589a-c80e-4b10-bf46-43c18380175e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  User ID Workout Type  Calories Burned  Workout Duration  Heart Rate  \\\n",
            "0  user_1     CrossFit              624                64         175   \n",
            "1  user_1     Strength              202                76         134   \n",
            "2  user_1        Dance              162                15         166   \n",
            "3  user_1        Zumba              512               112         111   \n",
            "4  user_2         HIIT              204                47          83   \n",
            "\n",
            "   VO2 Max  Age  Gender  Fitness Level  Time of Day  \n",
            "0    44.21   59       0              2            1  \n",
            "1    46.95   59       0              2            0  \n",
            "2    55.40   59       0              2            0  \n",
            "3    33.89   59       0              2            1  \n",
            "4    51.21   18       0              1            0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hybrid Recommendation System with Scikit-Learn**"
      ],
      "metadata": {
        "id": "odu870cjMPxr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Why Combine Methods?:** Collaborative filtering excels at capturing user-item interactions, while content-based filtering leverages user and item attributes. By combining these, the hybrid approach provides more personalized recommendations.\n",
        "\n",
        "In this implementation, I calculated user similarity based on collaborative filtering using a user-item interaction matrix. For the content-based filtering, I used features like demographics (e.g., age, gender, fitness level) and contextual data (e.g., time of day). By averaging the similarities from both approaches, I created a hybrid similarity matrix that balances interaction-based patterns with attribute-based insights.\n",
        "\n",
        "The hybrid approach improves recommendation relevance by addressing the cold-start problem for new users (via content attributes) while maintaining personalized recommendations based on past interactions."
      ],
      "metadata": {
        "id": "BzdsPudZ2q4L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize numeric features\n",
        "df_extended[['Calories Burned', 'Workout Duration', 'Heart Rate', 'VO2 Max', 'Age', 'Fitness Level']] = \\\n",
        "    scaler.fit_transform(df_extended[['Calories Burned', 'Workout Duration', 'Heart Rate', 'VO2 Max', 'Age', 'Fitness Level']])\n"
      ],
      "metadata": {
        "id": "lGLArhvfO4VI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Collaborative Filtering Matrix**"
      ],
      "metadata": {
        "id": "SozqbaHtQRpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# User-item interaction matrix\n",
        "interaction_matrix = pd.pivot_table(df_extended, index='User ID', columns='Workout Type', values='Calories Burned').fillna(0)\n",
        "user_similarity = cosine_similarity(interaction_matrix)\n"
      ],
      "metadata": {
        "id": "P2xtJX3zQPOH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Content-Based Matrix**"
      ],
      "metadata": {
        "id": "gFTYvZvHQhF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Content-based feature matrix\n",
        "content_features = df_extended[['User ID', 'Age', 'Gender', 'Fitness Level', 'Time of Day']].drop_duplicates(subset='User ID').set_index('User ID')\n",
        "content_similarity = cosine_similarity(content_features)\n"
      ],
      "metadata": {
        "id": "hGXLIQlyQbJf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hybrid Similarity**"
      ],
      "metadata": {
        "id": "OMXLLuFJQe0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine collaborative and content-based similarities\n",
        "hybrid_similarity = (user_similarity + content_similarity) / 2\n"
      ],
      "metadata": {
        "id": "Md_drkS7QdED"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Recommendation Function**"
      ],
      "metadata": {
        "id": "kgl6gxfNQvGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_workouts(user_id, num_recommendations=3):\n",
        "    similar_users = hybrid_similarity[user_ids.index(user_id)].argsort()[::-1]\n",
        "    recommended_workouts = []\n",
        "    for similar_user_idx in similar_users:\n",
        "        similar_user_id = user_ids[similar_user_idx]\n",
        "        user_workouts = df_extended[df_extended['User ID'] == similar_user_id]['Workout Type'].tolist()\n",
        "        recommended_workouts.extend(user_workouts)\n",
        "        if len(set(recommended_workouts)) >= num_recommendations:\n",
        "            break\n",
        "    return list(set(recommended_workouts))[:num_recommendations]\n",
        "\n",
        "# Test recommendations\n",
        "print(f\"Recommended Workouts for user_10: {recommend_workouts('user_10')}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELtthRQNQtWX",
        "outputId": "234112ab-868c-4ab4-e306-ef8ecddd9bbb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommended Workouts for user_10: ['Zumba', 'Strength', 'HIIT']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Evaluation**"
      ],
      "metadata": {
        "id": "8D79iAscQz2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate ground truth\n",
        "ground_truth = {user_id: random.sample(df_extended[df_extended['User ID'] == user_id]['Workout Type'].tolist(), 2)\n",
        "                for user_id in user_ids if len(df_extended[df_extended['User ID'] == user_id]['Workout Type']) >= 2}\n",
        "\n",
        "# Evaluate recommendations\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "\n",
        "for user_id, actual_workouts in ground_truth.items():\n",
        "    recommended_workouts = recommend_workouts(user_id, num_recommendations=3)\n",
        "    true_positives = len(set(recommended_workouts) & set(actual_workouts))\n",
        "    precision = true_positives / len(recommended_workouts) if recommended_workouts else 0\n",
        "    recall = true_positives / len(actual_workouts) if actual_workouts else 0\n",
        "\n",
        "    precision_scores.append(precision)\n",
        "    recall_scores.append(recall)\n",
        "\n",
        "# Average metrics\n",
        "average_precision = sum(precision_scores) / len(precision_scores)\n",
        "average_recall = sum(recall_scores) / len(recall_scores)\n",
        "\n",
        "print(f\"Average Precision: {average_precision:.2f}\")\n",
        "print(f\"Average Recall: {average_recall:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkoBo5tVQzaa",
        "outputId": "0da7f682-e99f-4e2d-f134-ebc1e73c23e3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Precision: 0.51\n",
            "Average Recall: 0.76\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results\n",
        "RMSE and MAE indicate prediction accuracy, while precision and recall evaluate recommendation relevance. The results showed reasonable accuracy and relevance, validating the model’s effectiveness.\n",
        "\n",
        "**Comparison and Limitations:** Comparing the baseline collaborative filtering with the hybrid model revealed improvements in precision and recall. However, synthetic data lacks real-world noise, which might limit generalizability. Future steps could involve testing on real-world datasets to validate the scalability and robustness of the hybrid approach."
      ],
      "metadata": {
        "id": "2AbhzO3V3gdC"
      }
    }
  ]
}